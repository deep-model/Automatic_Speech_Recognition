


[Linked White Paper](https://github.com/deep-model/Automatic_Speech_Recognition/blob/main/ASR_Report_M.Harper.pdf)
# AI-Driven Speech Recognition Models & End-to-End ASR 
# Using Nvidia NeMo toolkit ASR

This repository hosts a **GitHub Pagesâ€“optimized version** of the ASR Report by **Matthew Harper**.

**Abstract**: AI-based  speech recognition is a rapidly growing field of research which 
has transformed the way humans interact not only with machines but with each other. 
Speech recognition is considered a technology that enables machines to understand 
and interpret human speech [1]. Also known as automatic speech recognition (ASR), 
computer speech recognition or speech-to-text, is a capability that enables a 
program to process human speech into a written format. While speech recognition is
commonly confused with voice recognition, speech recognition focuses on the 
translation of speech from a verbal format to a text one whereas voice recognition 
just seeks to identify an individual userâ€™s voice [6]. This report provides a 
summary introduction into speech recognition models and illustrates a basic ASR 
model with the lab practicum. 

## ğŸ“„ Live Document
ğŸ‘‰ View the report here: [**GitHub Pages site**](https://github.com/deep-model/Automatic_Speech_Recognition/blob/main/ASR_Report_M.Harper.pdf)

## ğŸ“‚ Repository Structure
```
main/
 â”œâ”€â”€ ASR_Report_M.Harper.pdf
 â”œâ”€â”€ speech_recognition.py

docs/
 â”œâ”€â”€ index.md        # Main rendered document
 â”œâ”€â”€ page_merged.svg # Visual pages 1â€“15 (vector)
```

## ğŸ› ï¸ Formats Provided
- Markdown (semantic, searchable)
- SVG (high-fidelity visual reference)

## ğŸš€ Deployment
This site is deployed using **GitHub Pages** from the `/docs` directory.








